{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Periodicity Analysis\n",
    "\n",
    "Search for periodic signals and transits in cleaned TESS data.\n",
    "\n",
    "**Methods:**\n",
    "- Lomb-Scargle periodogram — find periodic variables\n",
    "- BLS (Box Least Squares) — find transit-like signals\n",
    "- Phase folding — visualize periodic signals\n",
    "\n",
    "**Data:** Sector 61, Camera 4, CCD 2 (cleaned with DataCleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project setup\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"pyproject.toml\").exists() or ((p / \"src\").exists() and (p / \"data\").exists()):\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "# Import project modules\n",
    "from tess.config import get_artifact_windows\n",
    "from tess.LightcurveBuilder import Lightcurve, lightcurve_from_cleaned\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# Sector config\n",
    "SECTOR = 61\n",
    "CAMERA = \"4\"\n",
    "CCD = \"2\"\n",
    "\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"Analyzing: Sector {SECTOR}, Camera {CAMERA}, CCD {CCD}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-cleaned",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLEANED photometry (with common-mode correction and masks)\n",
    "cleaned_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/cleaned/photometry_with_masks.parquet\"\n",
    "\n",
    "if cleaned_path.exists():\n",
    "    df = pd.read_parquet(cleaned_path)\n",
    "    print(f\"Loaded cleaned data: {cleaned_path}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    USE_CLEANED = True\n",
    "else:\n",
    "    # Fallback to raw photometry\n",
    "    raw_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/s{SECTOR:04d}_{CAMERA}-{CCD}_photometry.parquet\"\n",
    "    df = pd.read_parquet(raw_path)\n",
    "    print(f\"Loaded raw data: {raw_path}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    USE_CLEANED = False\n",
    "\n",
    "print(f\"\\nUsing cleaned data: {USE_CLEANED}\")\n",
    "print(f\"Stars: {df['star_id'].nunique()}\")\n",
    "print(f\"Epochs: {df['epoch'].nunique() if 'epoch' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ml-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML features for star selection\n",
    "ml_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/ml/ml_classification.parquet\"\n",
    "\n",
    "if ml_path.exists():\n",
    "    ml_df = pd.read_parquet(ml_path)\n",
    "    print(f\"Loaded ML features: {ml_path}\")\n",
    "    print(f\"Stars with features: {len(ml_df)}\")\n",
    "else:\n",
    "    ml_df = None\n",
    "    print(\"No ML features found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mask-bits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask bits explanation (if using cleaned data)\n",
    "if USE_CLEANED and 'mask' in df.columns:\n",
    "    print(\"Mask bits (uint16):\")\n",
    "    print(\"  Bit 0: quality    - TESS quality flag\")\n",
    "    print(\"  Bit 1: invalid    - NaN/negative flux\")\n",
    "    print(\"  Bit 2: bad_epoch  - High scatter epoch\")\n",
    "    print(\"  Bit 3: outlier_pos - Positive outlier (5σ)\")\n",
    "    print(\"  Bit 4: outlier_neg - Negative outlier (10σ)\")\n",
    "    print(\"  Bit 5: edge       - Star near CCD edge\")\n",
    "    print(\"  Bit 6: artifact   - Known artifact window\")\n",
    "    print(\"  Bit 7: low_snr    - Low signal-to-noise\")\n",
    "    \n",
    "    # Count masked points\n",
    "    print(f\"\\nTotal points: {len(df)}\")\n",
    "    print(f\"Good points (mask=0): {(df['mask'] == 0).sum()} ({(df['mask'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-header",
   "metadata": {},
   "source": [
    "## 2. Select Variable Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-candidates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stars likely to be variable (high amplitude, high chi2)\n",
    "if ml_df is not None:\n",
    "    # Filter by variability metrics\n",
    "    candidates = ml_df[\n",
    "        (ml_df['amplitude_robust'] > 0.01) &  # >1% amplitude\n",
    "        (ml_df['reduced_chi2'] > 1.0) &       # Significant variability\n",
    "        (ml_df['snr'] > 10)                   # Good SNR\n",
    "    ].copy()\n",
    "    \n",
    "    # Sort by amplitude\n",
    "    candidates = candidates.sort_values('amplitude_robust', ascending=False)\n",
    "    \n",
    "    print(f\"Variable candidates: {len(candidates)}\")\n",
    "    print(f\"\\nTop 10 by amplitude:\")\n",
    "    display(candidates[['star_id', 'tic_id', 'amplitude_robust', 'reduced_chi2', 'snr']].head(10))\n",
    "else:\n",
    "    # Use all stars if no ML features\n",
    "    candidates = pd.DataFrame({'star_id': df['star_id'].unique()})\n",
    "    print(f\"Using all {len(candidates)} stars (no ML features for filtering)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ls-header",
   "metadata": {},
   "source": [
    "## 3. Lomb-Scargle Periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lightcurve(star_id: str, cleaned_df: pd.DataFrame, for_transit: bool = False) -> Lightcurve:\n",
    "    \"\"\"Get Lightcurve object using project's lightcurve_from_cleaned function.\"\"\"\n",
    "    return lightcurve_from_cleaned(star_id, cleaned_df, use_flux_cm=True, for_transit=for_transit)\n",
    "\n",
    "\n",
    "def run_lomb_scargle(lc: Lightcurve, min_period=0.1, max_period=15.0):\n",
    "    \"\"\"Run Lomb-Scargle on a Lightcurve object.\"\"\"\n",
    "    from scipy.signal import lombscargle\n",
    "\n",
    "    time, flux, _ = lc.to_arrays(good_only=True)\n",
    "\n",
    "    if len(time) < 50:\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Normalize\n",
    "    flux_norm = flux / np.median(flux)\n",
    "\n",
    "    # Shift time, center flux\n",
    "    t0 = time - time.min()\n",
    "    flux_centered = flux_norm - np.mean(flux_norm)\n",
    "\n",
    "    # Frequency grid\n",
    "    freqs = np.linspace(1/max_period, 1/min_period, 10000)\n",
    "    angular_freqs = 2 * np.pi * freqs\n",
    "\n",
    "    # Compute periodogram\n",
    "    power = lombscargle(t0, flux_centered, angular_freqs, normalize=True)\n",
    "    periods = 1 / freqs\n",
    "\n",
    "    # Find best period\n",
    "    best_idx = np.argmax(power)\n",
    "\n",
    "    return periods, power, periods[best_idx], power[best_idx]\n",
    "\n",
    "\n",
    "print(\"Functions defined:\")\n",
    "print(\"  get_lightcurve() - uses project's lightcurve_from_cleaned()\")\n",
    "print(\"  run_lomb_scargle() - runs periodogram on Lightcurve object\")\n",
    "print(\"  Lightcurve has: .fold(), .plot_folded(), .bls_periodogram()\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lomb-Scargle on top candidates\n",
    "N_ANALYZE = min(100, len(candidates))\n",
    "print(f\"Analyzing {N_ANALYZE} candidates...\")\n",
    "\n",
    "ls_results = []\n",
    "\n",
    "for i, (_, row) in enumerate(candidates.head(N_ANALYZE).iterrows()):\n",
    "    star_id = row['star_id']\n",
    "    tic_id = row.get('tic_id', None)\n",
    "\n",
    "    try:\n",
    "        lc = get_lightcurve(star_id, df, for_transit=False)\n",
    "        periods, power, best_period, best_power = run_lomb_scargle(lc)\n",
    "\n",
    "        if best_period is not None:\n",
    "            ls_results.append({\n",
    "                'star_id': star_id,\n",
    "                'tic_id': tic_id,\n",
    "                'best_period': best_period,\n",
    "                'ls_power': best_power,\n",
    "                'n_points': lc.stats['n_good'],\n",
    "                'amplitude_robust': row.get('amplitude_robust', None)\n",
    "            })\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Processed {i+1}/{N_ANALYZE}\")\n",
    "\n",
    "ls_df = pd.DataFrame(ls_results)\n",
    "ls_df = ls_df.sort_values('ls_power', ascending=False)\n",
    "\n",
    "print(f\"\\nCompleted. Found periods for {len(ls_df)} stars.\")\n",
    "print(f\"\\nTop 15 by Lomb-Scargle power:\")\n",
    "display(ls_df.head(15))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase-header",
   "metadata": {},
   "source": [
    "## 4. Phase Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_star_analysis(star_id, tic_id, cleaned_df):\n",
    "    \"\"\"Plot raw lightcurve, periodogram, and phase-folded using Lightcurve class.\"\"\"\n",
    "    lc = get_lightcurve(star_id, cleaned_df, for_transit=False)\n",
    "\n",
    "    if lc.stats['n_good'] < 50:\n",
    "        print(f\"Not enough data for {star_id}\")\n",
    "        return None, None\n",
    "\n",
    "    # Compute periodogram\n",
    "    periods, power, best_period, best_power = run_lomb_scargle(lc)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # 1. Raw lightcurve - use Lightcurve.plot()\n",
    "    lc.normalize().plot(ax=axes[0, 0], show_errors=False)\n",
    "    axes[0, 0].set_title(f'{star_id} (TIC {tic_id}) - Raw Lightcurve')\n",
    "\n",
    "    # 2. Periodogram\n",
    "    axes[0, 1].plot(periods, power, 'b-', lw=0.5)\n",
    "    axes[0, 1].axvline(best_period, color='red', ls='--', label=f'Best: {best_period:.4f} d')\n",
    "    axes[0, 1].set_xlabel('Period (days)')\n",
    "    axes[0, 1].set_ylabel('Lomb-Scargle Power')\n",
    "    axes[0, 1].set_title('Periodogram')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].set_xlim(0, 15)\n",
    "\n",
    "    # 3. Phase-folded (best period) - use Lightcurve.plot_folded()\n",
    "    lc.normalize().plot_folded(best_period, ax=axes[1, 0], show_binned=True)\n",
    "    axes[1, 0].set_title(f'Phase-folded (P = {best_period:.4f} d)')\n",
    "\n",
    "    # 4. Phase-folded (double period)\n",
    "    period_2x = best_period * 2\n",
    "    lc.normalize().plot_folded(period_2x, ax=axes[1, 1], show_binned=True)\n",
    "    axes[1, 1].set_title(f'Phase-folded (P = {period_2x:.4f} d, x2)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, best_period\n",
    "\n",
    "\n",
    "print(\"Function defined: plot_star_analysis()\")\n",
    "print(\"Uses Lightcurve.plot(), .normalize(), .plot_folded()\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-top",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 6 periodic candidates\n",
    "N_PLOT = 6\n",
    "\n",
    "for i, (_, row) in enumerate(ls_df.head(N_PLOT).iterrows()):\n",
    "    fig, period = plot_star_analysis(row['star_id'], row['tic_id'], df, USE_CLEANED)\n",
    "    plt.show()\n",
    "    print(f\"Star {i+1}: {row['star_id']} | TIC {row['tic_id']} | P = {period:.4f} d | LS Power = {row['ls_power']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bls-header",
   "metadata": {},
   "source": [
    "## 5. BLS Transit Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bls-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bls_search(time, flux, periods, duration_frac=0.02):\n",
    "    \"\"\"Simple BLS-like transit search.\n",
    "    \n",
    "    For production use, prefer astropy.timeseries.BoxLeastSquares.\n",
    "    \"\"\"\n",
    "    if len(time) < 50:\n",
    "        return None, None, None\n",
    "    \n",
    "    t0 = time - time.min()\n",
    "    \n",
    "    best_power = 0\n",
    "    best_period = None\n",
    "    best_depth = 0\n",
    "    powers = []\n",
    "    \n",
    "    for period in periods:\n",
    "        phase = (t0 / period) % 1.0\n",
    "        \n",
    "        # Try different transit phases\n",
    "        n_phase_bins = 20\n",
    "        period_best_power = 0\n",
    "        \n",
    "        for phase_start in np.linspace(0, 1 - duration_frac, n_phase_bins):\n",
    "            in_transit = (phase >= phase_start) & (phase < phase_start + duration_frac)\n",
    "            out_transit = ~in_transit\n",
    "            \n",
    "            if in_transit.sum() < 3 or out_transit.sum() < 10:\n",
    "                continue\n",
    "            \n",
    "            f_in = np.median(flux[in_transit])\n",
    "            f_out = np.median(flux[out_transit])\n",
    "            depth = f_out - f_in\n",
    "            \n",
    "            if depth > 0:\n",
    "                n_in, n_out = in_transit.sum(), out_transit.sum()\n",
    "                power = depth * np.sqrt(n_in * n_out / (n_in + n_out))\n",
    "                \n",
    "                period_best_power = max(period_best_power, power)\n",
    "                \n",
    "                if power > best_power:\n",
    "                    best_power = power\n",
    "                    best_period = period\n",
    "                    best_depth = depth\n",
    "        \n",
    "        powers.append(period_best_power)\n",
    "    \n",
    "    return best_period, best_power, best_depth\n",
    "\n",
    "\n",
    "print(\"Function defined: bls_search()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bls-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for transits using Lightcurve with for_transit=True\n",
    "if ml_df is not None:\n",
    "    transit_candidates = ml_df[\n",
    "        (ml_df['amplitude_robust'] < 0.03) &\n",
    "        (ml_df['amplitude_robust'] > 0.001) &\n",
    "        (ml_df['snr'] > 20)\n",
    "    ].copy()\n",
    "    transit_candidates = transit_candidates.sort_values('snr', ascending=False)\n",
    "else:\n",
    "    transit_candidates = candidates\n",
    "\n",
    "print(f\"Transit candidates: {len(transit_candidates)}\")\n",
    "\n",
    "# Run BLS using Lightcurve.bls_periodogram()\n",
    "N_BLS = min(50, len(transit_candidates))\n",
    "print(f\"\\nRunning BLS on {N_BLS} stars (using Lightcurve.bls_periodogram)...\")\n",
    "\n",
    "bls_results = []\n",
    "\n",
    "for i, (_, row) in enumerate(transit_candidates.head(N_BLS).iterrows()):\n",
    "    star_id = row['star_id']\n",
    "\n",
    "    try:\n",
    "        # Use for_transit=True to keep outliers\n",
    "        lc = get_lightcurve(star_id, df, for_transit=True)\n",
    "\n",
    "        # Use Lightcurve's bls_periodogram method\n",
    "        bls_result = lc.bls_periodogram(min_period=0.5, max_period=10.0)\n",
    "\n",
    "        if bls_result and bls_result.get('best_depth', 0) > 0.005:\n",
    "            bls_results.append({\n",
    "                'star_id': star_id,\n",
    "                'tic_id': row.get('tic_id', None),\n",
    "                'period': bls_result['best_period'],\n",
    "                'depth_pct': bls_result['best_depth'] * 100,\n",
    "                'bls_power': bls_result['best_power'],\n",
    "                'snr': row.get('snr', None)\n",
    "            })\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i+1}/{N_BLS}\")\n",
    "\n",
    "bls_df = pd.DataFrame(bls_results)\n",
    "if len(bls_df) > 0:\n",
    "    bls_df = bls_df.sort_values('bls_power', ascending=False)\n",
    "    print(f\"\\nFound {len(bls_df)} potential transit signals:\")\n",
    "    display(bls_df.head(10))\n",
    "else:\n",
    "    print(\"\\nNo significant transit signals found.\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export periodicity results\n",
    "output_dir = PROJECT_ROOT / f\"variable_stars/sector_{SECTOR:03d}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save Lomb-Scargle results\n",
    "ls_path = output_dir / 'periodicity_lomb_scargle.csv'\n",
    "ls_df.to_csv(ls_path, index=False)\n",
    "print(f\"Lomb-Scargle results saved to: {ls_path}\")\n",
    "\n",
    "# Save BLS results\n",
    "if len(bls_df) > 0:\n",
    "    bls_path = output_dir / 'periodicity_bls_transits.csv'\n",
    "    bls_df.to_csv(bls_path, index=False)\n",
    "    print(f\"BLS results saved to: {bls_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plots for top candidates\n",
    "plots_dir = output_dir / 'periodicity_plots'\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "N_SAVE = 10\n",
    "print(f\"Saving plots for top {N_SAVE} periodic candidates...\")\n",
    "\n",
    "for i, (_, row) in enumerate(ls_df.head(N_SAVE).iterrows()):\n",
    "    fig, period = plot_star_analysis(row['star_id'], row['tic_id'], df, USE_CLEANED)\n",
    "    \n",
    "    filename = f\"{row['star_id']}_TIC{row['tic_id']}_P{period:.4f}d.png\"\n",
    "    fig.savefig(plots_dir / filename, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Plots saved to: {plots_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook analyzed cleaned TESS data for periodic signals:\n",
    "\n",
    "1. **Lomb-Scargle** — found periodic variables (eclipsing binaries, pulsators, rotators)\n",
    "2. **BLS** — searched for transit-like signals (potential exoplanets)\n",
    "3. **Phase folding** — visualized periodic signals with single and double periods\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `variable_stars/sector_061/periodicity_lomb_scargle.csv` — Periods and LS power\n",
    "- `variable_stars/sector_061/periodicity_bls_transits.csv` — Transit candidates\n",
    "- `variable_stars/sector_061/periodicity_plots/` — Phase-folded plots\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Cross-match periodic stars with VSX\n",
    "2. Verify transit candidates on ExoFOP\n",
    "3. Submit new discoveries to VSX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}