{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Periodicity Analysis\n",
    "\n",
    "Search for periodic signals and transits in cleaned TESS data.\n",
    "\n",
    "**Methods:**\n",
    "- Lomb-Scargle periodogram — find periodic variables\n",
    "- BLS (Box Least Squares) — find transit-like signals\n",
    "- Phase folding — visualize periodic signals\n",
    "\n",
    "**Data:** Sector 61, Camera 4, CCD 2 (cleaned with DataCleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lombscargle\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Project setup\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"pyproject.toml\").exists() or ((p / \"src\").exists() and (p / \"data\").exists()):\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from tess.config import get_artifact_windows\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# Sector config\n",
    "SECTOR = 61\n",
    "CAMERA = \"4\"\n",
    "CCD = \"2\"\n",
    "\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"Analyzing: Sector {SECTOR}, Camera {CAMERA}, CCD {CCD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-cleaned",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLEANED photometry (with common-mode correction and masks)\n",
    "cleaned_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/cleaned/photometry_with_masks.parquet\"\n",
    "\n",
    "if cleaned_path.exists():\n",
    "    df = pd.read_parquet(cleaned_path)\n",
    "    print(f\"Loaded cleaned data: {cleaned_path}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    USE_CLEANED = True\n",
    "else:\n",
    "    # Fallback to raw photometry\n",
    "    raw_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/s{SECTOR:04d}_{CAMERA}-{CCD}_photometry.parquet\"\n",
    "    df = pd.read_parquet(raw_path)\n",
    "    print(f\"Loaded raw data: {raw_path}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    USE_CLEANED = False\n",
    "\n",
    "print(f\"\\nUsing cleaned data: {USE_CLEANED}\")\n",
    "print(f\"Stars: {df['star_id'].nunique()}\")\n",
    "print(f\"Epochs: {df['epoch'].nunique() if 'epoch' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-ml-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML features for star selection\n",
    "ml_path = DATA_DIR / f\"tess/sector_{SECTOR:03d}/cam{CAMERA}_ccd{CCD}/ml/ml_classification.parquet\"\n",
    "\n",
    "if ml_path.exists():\n",
    "    ml_df = pd.read_parquet(ml_path)\n",
    "    print(f\"Loaded ML features: {ml_path}\")\n",
    "    print(f\"Stars with features: {len(ml_df)}\")\n",
    "else:\n",
    "    ml_df = None\n",
    "    print(\"No ML features found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mask-bits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask bits explanation (if using cleaned data)\n",
    "if USE_CLEANED and 'mask' in df.columns:\n",
    "    print(\"Mask bits (uint16):\")\n",
    "    print(\"  Bit 0: quality    - TESS quality flag\")\n",
    "    print(\"  Bit 1: invalid    - NaN/negative flux\")\n",
    "    print(\"  Bit 2: bad_epoch  - High scatter epoch\")\n",
    "    print(\"  Bit 3: outlier_pos - Positive outlier (5σ)\")\n",
    "    print(\"  Bit 4: outlier_neg - Negative outlier (10σ)\")\n",
    "    print(\"  Bit 5: edge       - Star near CCD edge\")\n",
    "    print(\"  Bit 6: artifact   - Known artifact window\")\n",
    "    print(\"  Bit 7: low_snr    - Low signal-to-noise\")\n",
    "    \n",
    "    # Count masked points\n",
    "    print(f\"\\nTotal points: {len(df)}\")\n",
    "    print(f\"Good points (mask=0): {(df['mask'] == 0).sum()} ({(df['mask'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-header",
   "metadata": {},
   "source": [
    "## 2. Select Variable Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-candidates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stars likely to be variable (high amplitude, high chi2)\n",
    "if ml_df is not None:\n",
    "    # Filter by variability metrics\n",
    "    candidates = ml_df[\n",
    "        (ml_df['amplitude_robust'] > 0.01) &  # >1% amplitude\n",
    "        (ml_df['reduced_chi2'] > 1.0) &       # Significant variability\n",
    "        (ml_df['snr'] > 10)                   # Good SNR\n",
    "    ].copy()\n",
    "    \n",
    "    # Sort by amplitude\n",
    "    candidates = candidates.sort_values('amplitude_robust', ascending=False)\n",
    "    \n",
    "    print(f\"Variable candidates: {len(candidates)}\")\n",
    "    print(f\"\\nTop 10 by amplitude:\")\n",
    "    display(candidates[['star_id', 'tic_id', 'amplitude_robust', 'reduced_chi2', 'snr']].head(10))\n",
    "else:\n",
    "    # Use all stars if no ML features\n",
    "    candidates = pd.DataFrame({'star_id': df['star_id'].unique()})\n",
    "    print(f\"Using all {len(candidates)} stars (no ML features for filtering)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ls-header",
   "metadata": {},
   "source": [
    "## 3. Lomb-Scargle Periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_lightcurve(star_id, df, use_cleaned=True):\n",
    "    \"\"\"Extract clean lightcurve for a star.\"\"\"\n",
    "    star_df = df[df['star_id'] == star_id].copy()\n",
    "    \n",
    "    # Use flux_cm if available, else flux\n",
    "    if use_cleaned and 'flux_cm' in star_df.columns:\n",
    "        flux_col = 'flux_cm'\n",
    "    else:\n",
    "        flux_col = 'flux'\n",
    "    \n",
    "    # Apply mask if available\n",
    "    if 'mask' in star_df.columns:\n",
    "        star_df = star_df[star_df['mask'] == 0]\n",
    "    elif 'quality' in star_df.columns:\n",
    "        star_df = star_df[star_df['quality'] == 0]\n",
    "    \n",
    "    # Get time and flux\n",
    "    time = star_df['btjd'].values\n",
    "    flux = star_df[flux_col].values\n",
    "    \n",
    "    # Remove NaN\n",
    "    mask = np.isfinite(time) & np.isfinite(flux)\n",
    "    time, flux = time[mask], flux[mask]\n",
    "    \n",
    "    # Normalize\n",
    "    if len(flux) > 0:\n",
    "        median = np.median(flux)\n",
    "        if median > 0:\n",
    "            flux = flux / median\n",
    "    \n",
    "    return time, flux\n",
    "\n",
    "\n",
    "def lomb_scargle_periodogram(time, flux, min_period=0.1, max_period=15.0, n_freqs=10000):\n",
    "    \"\"\"Compute Lomb-Scargle periodogram.\"\"\"\n",
    "    if len(time) < 50:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Shift time to start at 0 (numerical stability)\n",
    "    t0 = time - time.min()\n",
    "    \n",
    "    # Center flux\n",
    "    flux_centered = flux - np.mean(flux)\n",
    "    \n",
    "    # Frequency grid\n",
    "    freqs = np.linspace(1/max_period, 1/min_period, n_freqs)\n",
    "    angular_freqs = 2 * np.pi * freqs\n",
    "    \n",
    "    # Compute periodogram\n",
    "    power = lombscargle(t0, flux_centered, angular_freqs, normalize=True)\n",
    "    periods = 1 / freqs\n",
    "    \n",
    "    # Find best period\n",
    "    best_idx = np.argmax(power)\n",
    "    best_period = periods[best_idx]\n",
    "    best_power = power[best_idx]\n",
    "    \n",
    "    return periods, power, best_period, best_power\n",
    "\n",
    "\n",
    "print(\"Functions defined: get_star_lightcurve(), lomb_scargle_periodogram()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ls-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lomb-Scargle on top candidates\n",
    "N_ANALYZE = min(100, len(candidates))\n",
    "print(f\"Analyzing {N_ANALYZE} candidates...\")\n",
    "\n",
    "ls_results = []\n",
    "\n",
    "for i, (_, row) in enumerate(candidates.head(N_ANALYZE).iterrows()):\n",
    "    star_id = row['star_id']\n",
    "    tic_id = row.get('tic_id', None)\n",
    "    \n",
    "    time, flux = get_star_lightcurve(star_id, df, USE_CLEANED)\n",
    "    \n",
    "    if len(time) < 50:\n",
    "        continue\n",
    "    \n",
    "    periods, power, best_period, best_power = lomb_scargle_periodogram(time, flux)\n",
    "    \n",
    "    if best_period is not None:\n",
    "        ls_results.append({\n",
    "            'star_id': star_id,\n",
    "            'tic_id': tic_id,\n",
    "            'best_period': best_period,\n",
    "            'ls_power': best_power,\n",
    "            'n_points': len(time),\n",
    "            'amplitude_robust': row.get('amplitude_robust', None)\n",
    "        })\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Processed {i+1}/{N_ANALYZE}\")\n",
    "\n",
    "ls_df = pd.DataFrame(ls_results)\n",
    "ls_df = ls_df.sort_values('ls_power', ascending=False)\n",
    "\n",
    "print(f\"\\nCompleted. Found periods for {len(ls_df)} stars.\")\n",
    "print(f\"\\nTop 15 by Lomb-Scargle power:\")\n",
    "display(ls_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase-header",
   "metadata": {},
   "source": [
    "## 4. Phase Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_star_analysis(star_id, tic_id, df, use_cleaned=True):\n",
    "    \"\"\"Plot raw lightcurve, periodogram, and phase-folded curve.\"\"\"\n",
    "    time, flux = get_star_lightcurve(star_id, df, use_cleaned)\n",
    "    \n",
    "    if len(time) < 50:\n",
    "        print(f\"Not enough data for {star_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Compute periodogram\n",
    "    periods, power, best_period, best_power = lomb_scargle_periodogram(time, flux)\n",
    "    \n",
    "    # Check double period\n",
    "    period_2x = best_period * 2\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Raw lightcurve\n",
    "    axes[0, 0].scatter(time, flux, s=2, alpha=0.5)\n",
    "    axes[0, 0].axhline(1.0, color='gray', ls='--', alpha=0.5)\n",
    "    axes[0, 0].set_xlabel('BTJD')\n",
    "    axes[0, 0].set_ylabel('Normalized Flux')\n",
    "    axes[0, 0].set_title(f'{star_id} (TIC {tic_id}) - Raw Lightcurve')\n",
    "    \n",
    "    # 2. Periodogram\n",
    "    axes[0, 1].plot(periods, power, 'b-', lw=0.5)\n",
    "    axes[0, 1].axvline(best_period, color='red', ls='--', label=f'Best: {best_period:.4f} d')\n",
    "    axes[0, 1].set_xlabel('Period (days)')\n",
    "    axes[0, 1].set_ylabel('Lomb-Scargle Power')\n",
    "    axes[0, 1].set_title('Periodogram')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].set_xlim(0, 15)\n",
    "    \n",
    "    # 3. Phase-folded (best period)\n",
    "    phase = ((time - time.min()) / best_period) % 1.0\n",
    "    phase = np.where(phase > 0.5, phase - 1.0, phase)\n",
    "    \n",
    "    # Bin\n",
    "    n_bins = 50\n",
    "    bin_edges = np.linspace(-0.5, 0.5, n_bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    bin_means = [np.median(flux[(phase >= bin_edges[i]) & (phase < bin_edges[i+1])]) \n",
    "                 if ((phase >= bin_edges[i]) & (phase < bin_edges[i+1])).sum() > 0 else np.nan\n",
    "                 for i in range(n_bins)]\n",
    "    \n",
    "    axes[1, 0].scatter(phase, flux, s=2, alpha=0.3)\n",
    "    axes[1, 0].plot(bin_centers, bin_means, 'o-', color='orange', markersize=3)\n",
    "    axes[1, 0].axhline(1.0, color='gray', ls='--', alpha=0.5)\n",
    "    axes[1, 0].set_xlabel('Phase')\n",
    "    axes[1, 0].set_ylabel('Normalized Flux')\n",
    "    axes[1, 0].set_title(f'Phase-folded (P = {best_period:.4f} d)')\n",
    "    \n",
    "    # 4. Phase-folded (double period) - for eclipsing binaries\n",
    "    phase_2x = ((time - time.min()) / period_2x) % 1.0\n",
    "    phase_2x = np.where(phase_2x > 0.5, phase_2x - 1.0, phase_2x)\n",
    "    \n",
    "    bin_means_2x = [np.median(flux[(phase_2x >= bin_edges[i]) & (phase_2x < bin_edges[i+1])]) \n",
    "                    if ((phase_2x >= bin_edges[i]) & (phase_2x < bin_edges[i+1])).sum() > 0 else np.nan\n",
    "                    for i in range(n_bins)]\n",
    "    \n",
    "    axes[1, 1].scatter(phase_2x, flux, s=2, alpha=0.3)\n",
    "    axes[1, 1].plot(bin_centers, bin_means_2x, 'o-', color='orange', markersize=3)\n",
    "    axes[1, 1].axhline(1.0, color='gray', ls='--', alpha=0.5)\n",
    "    axes[1, 1].set_xlabel('Phase')\n",
    "    axes[1, 1].set_ylabel('Normalized Flux')\n",
    "    axes[1, 1].set_title(f'Phase-folded (P = {period_2x:.4f} d, x2)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, best_period\n",
    "\n",
    "\n",
    "print(\"Function defined: plot_star_analysis()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-top",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 6 periodic candidates\n",
    "N_PLOT = 6\n",
    "\n",
    "for i, (_, row) in enumerate(ls_df.head(N_PLOT).iterrows()):\n",
    "    fig, period = plot_star_analysis(row['star_id'], row['tic_id'], df, USE_CLEANED)\n",
    "    plt.show()\n",
    "    print(f\"Star {i+1}: {row['star_id']} | TIC {row['tic_id']} | P = {period:.4f} d | LS Power = {row['ls_power']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bls-header",
   "metadata": {},
   "source": [
    "## 5. BLS Transit Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bls-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bls_search(time, flux, periods, duration_frac=0.02):\n",
    "    \"\"\"Simple BLS-like transit search.\n",
    "    \n",
    "    For production use, prefer astropy.timeseries.BoxLeastSquares.\n",
    "    \"\"\"\n",
    "    if len(time) < 50:\n",
    "        return None, None, None\n",
    "    \n",
    "    t0 = time - time.min()\n",
    "    \n",
    "    best_power = 0\n",
    "    best_period = None\n",
    "    best_depth = 0\n",
    "    powers = []\n",
    "    \n",
    "    for period in periods:\n",
    "        phase = (t0 / period) % 1.0\n",
    "        \n",
    "        # Try different transit phases\n",
    "        n_phase_bins = 20\n",
    "        period_best_power = 0\n",
    "        \n",
    "        for phase_start in np.linspace(0, 1 - duration_frac, n_phase_bins):\n",
    "            in_transit = (phase >= phase_start) & (phase < phase_start + duration_frac)\n",
    "            out_transit = ~in_transit\n",
    "            \n",
    "            if in_transit.sum() < 3 or out_transit.sum() < 10:\n",
    "                continue\n",
    "            \n",
    "            f_in = np.median(flux[in_transit])\n",
    "            f_out = np.median(flux[out_transit])\n",
    "            depth = f_out - f_in\n",
    "            \n",
    "            if depth > 0:\n",
    "                n_in, n_out = in_transit.sum(), out_transit.sum()\n",
    "                power = depth * np.sqrt(n_in * n_out / (n_in + n_out))\n",
    "                \n",
    "                period_best_power = max(period_best_power, power)\n",
    "                \n",
    "                if power > best_power:\n",
    "                    best_power = power\n",
    "                    best_period = period\n",
    "                    best_depth = depth\n",
    "        \n",
    "        powers.append(period_best_power)\n",
    "    \n",
    "    return best_period, best_power, best_depth\n",
    "\n",
    "\n",
    "print(\"Function defined: bls_search()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bls-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for transits in low-amplitude stars (potential planet hosts)\n",
    "if ml_df is not None:\n",
    "    transit_candidates = ml_df[\n",
    "        (ml_df['amplitude_robust'] < 0.03) &  # Low amplitude (not eclipsing binary)\n",
    "        (ml_df['amplitude_robust'] > 0.001) & # Some variation\n",
    "        (ml_df['snr'] > 20)                   # Good SNR\n",
    "    ].copy()\n",
    "    transit_candidates = transit_candidates.sort_values('snr', ascending=False)\n",
    "else:\n",
    "    transit_candidates = candidates\n",
    "\n",
    "print(f\"Transit candidates: {len(transit_candidates)}\")\n",
    "\n",
    "# Run BLS\n",
    "N_BLS = min(50, len(transit_candidates))\n",
    "bls_periods = np.linspace(0.5, 10.0, 200)\n",
    "\n",
    "print(f\"\\nRunning BLS on {N_BLS} stars...\")\n",
    "\n",
    "bls_results = []\n",
    "\n",
    "for i, (_, row) in enumerate(transit_candidates.head(N_BLS).iterrows()):\n",
    "    star_id = row['star_id']\n",
    "    time, flux = get_star_lightcurve(star_id, df, USE_CLEANED)\n",
    "    \n",
    "    if len(time) < 100:\n",
    "        continue\n",
    "    \n",
    "    period, power, depth = bls_search(time, flux, bls_periods)\n",
    "    \n",
    "    if period is not None and depth > 0.005:  # >0.5% depth\n",
    "        bls_results.append({\n",
    "            'star_id': star_id,\n",
    "            'tic_id': row.get('tic_id', None),\n",
    "            'period': period,\n",
    "            'depth_pct': depth * 100,\n",
    "            'bls_power': power,\n",
    "            'snr': row.get('snr', None)\n",
    "        })\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i+1}/{N_BLS}\")\n",
    "\n",
    "bls_df = pd.DataFrame(bls_results)\n",
    "if len(bls_df) > 0:\n",
    "    bls_df = bls_df.sort_values('bls_power', ascending=False)\n",
    "    print(f\"\\nFound {len(bls_df)} potential transit signals:\")\n",
    "    display(bls_df.head(10))\n",
    "else:\n",
    "    print(\"\\nNo significant transit signals found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export periodicity results\n",
    "output_dir = PROJECT_ROOT / f\"variable_stars/sector_{SECTOR:03d}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save Lomb-Scargle results\n",
    "ls_path = output_dir / 'periodicity_lomb_scargle.csv'\n",
    "ls_df.to_csv(ls_path, index=False)\n",
    "print(f\"Lomb-Scargle results saved to: {ls_path}\")\n",
    "\n",
    "# Save BLS results\n",
    "if len(bls_df) > 0:\n",
    "    bls_path = output_dir / 'periodicity_bls_transits.csv'\n",
    "    bls_df.to_csv(bls_path, index=False)\n",
    "    print(f\"BLS results saved to: {bls_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plots for top candidates\n",
    "plots_dir = output_dir / 'periodicity_plots'\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "N_SAVE = 10\n",
    "print(f\"Saving plots for top {N_SAVE} periodic candidates...\")\n",
    "\n",
    "for i, (_, row) in enumerate(ls_df.head(N_SAVE).iterrows()):\n",
    "    fig, period = plot_star_analysis(row['star_id'], row['tic_id'], df, USE_CLEANED)\n",
    "    \n",
    "    filename = f\"{row['star_id']}_TIC{row['tic_id']}_P{period:.4f}d.png\"\n",
    "    fig.savefig(plots_dir / filename, dpi=100, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Plots saved to: {plots_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook analyzed cleaned TESS data for periodic signals:\n",
    "\n",
    "1. **Lomb-Scargle** — found periodic variables (eclipsing binaries, pulsators, rotators)\n",
    "2. **BLS** — searched for transit-like signals (potential exoplanets)\n",
    "3. **Phase folding** — visualized periodic signals with single and double periods\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `variable_stars/sector_061/periodicity_lomb_scargle.csv` — Periods and LS power\n",
    "- `variable_stars/sector_061/periodicity_bls_transits.csv` — Transit candidates\n",
    "- `variable_stars/sector_061/periodicity_plots/` — Phase-folded plots\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Cross-match periodic stars with VSX\n",
    "2. Verify transit candidates on ExoFOP\n",
    "3. Submit new discoveries to VSX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
